{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f75c881-bbc9-43ab-a33b-1fb506c7b896",
   "metadata": {},
   "source": [
    "# **DACON-GAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5f842-6662-4659-8ff7-6c4483d36acf",
   "metadata": {},
   "source": [
    "## **Default Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "460c5cc9-92c4-4430-b957-72f20917f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VERSION]\n",
      "torch: 1.9.0+cu111\n",
      "transformers: 4.11.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"[VERSION]\")\n",
    "print(f\"torch: {torch.__version__}\")\n",
    "print(f\"transformers: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f221ddb6-ca78-4251-8d8c-c27c52456786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data': PosixPath('data'),\n",
      "    'tr_data': PosixPath('data/train'),\n",
      "    'tr_law_data': PosixPath('data/train/tr_law_data.json'),\n",
      "    'tr_journal_data': PosixPath('data/train/tr_journal_data.json'),\n",
      "    'tr_article_data': PosixPath('data/train/tr_article_data.json'),\n",
      "    'vl_data': PosixPath('data/train/validate'),\n",
      "    'vl_law_data': PosixPath('data/train/validate/vl_law_data.json'),\n",
      "    'vl_journal_data': PosixPath('data/train/validate/vl_journal_data.json'),\n",
      "    'vl_article_data': PosixPath('data/train/validate/vl_article_data.json')}\n"
     ]
    }
   ],
   "source": [
    "class HParams(object):\n",
    "    def __init__(self):\n",
    "        ## Path.\n",
    "        self.data = Path(\"data\") ## 문서요약 텍스트\n",
    "        \n",
    "        self.tr_data = self.data / Path(\"train\")\n",
    "        self.tr_law_data = self.tr_data / Path(\"tr_law_data.json\")\n",
    "        self.tr_journal_data = self.tr_data / Path(\"tr_journal_data.json\")\n",
    "        self.tr_article_data = self.tr_data / Path(\"tr_article_data.json\")\n",
    "\n",
    "        self.vl_data = self.tr_data / Path(\"validate\")\n",
    "        self.vl_law_data = self.vl_data / Path(\"vl_law_data.json\")\n",
    "        self.vl_journal_data = self.vl_data / Path(\"vl_journal_data.json\")\n",
    "        self.vl_article_data = self.vl_data / Path(\"vl_article_data.json\")\n",
    "        \n",
    "args = HParams()\n",
    "pprint.PrettyPrinter(indent=4, sort_dicts=False).pprint(vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f88f4f-f738-4308-a089-b854a70313b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 21 08:08:09 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.74       Driver Version: 470.74       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "|  0%   36C    P8    23W / 220W |     68MiB /  7979MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       987      G   /usr/lib/xorg/Xorg                 56MiB |\n",
      "|    0   N/A  N/A      1105      G   /usr/bin/gnome-shell                9MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           31Gi       1.4Gi        25Gi       3.0Mi       4.8Gi        29Gi\n",
      "Swap:         2.0Gi          0B       2.0Gi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi; free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdbc55c-abd8-415b-8920-f0c9f8fb5aee",
   "metadata": {},
   "source": [
    "## **Prepare Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47c3aa-1e58-4224-9361-27f5e6b3ac5e",
   "metadata": {},
   "source": [
    "### **Naming**\n",
    "\n",
    "제공받은 데이터세트의 이름을 조금 변경했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c56e4a40-5e64-4185-82d5-00485e1484f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\n",
      "├── [4.0K]  \u001b[01;34mdata\u001b[00m\n",
      "│   ├── [4.0K]  \u001b[01;34mtrain\u001b[00m\n",
      "│   │   ├── [1.2G]  tr_article_data.json\n",
      "│   │   ├── [346M]  tr_journal_data.json\n",
      "│   │   └── [ 90M]  tr_law_data.json\n",
      "│   └── [4.0K]  \u001b[01;34mvalidate\u001b[00m\n",
      "│       ├── [140M]  vl_article_data.json\n",
      "│       ├── [ 35M]  vl_journal_data.json\n",
      "│       └── [8.5M]  vl_law_data.json\n",
      "└── [4.7K]  main.ipynb\n",
      "\n",
      "3 directories, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree -alh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e984b-8950-401c-a73d-ae39dcc14a64",
   "metadata": {},
   "source": [
    "### **Data Format**\n",
    "\n",
    "참조: https://aihub.or.kr/aidata/8054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cb84046-72af-4616-b314-e97d507f9316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'name': '법률문서 프로젝트',\n",
      "    'delivery_date': '2020-12-23 17:23:13',\n",
      "    'documents': [   {   'id': '100004',\n",
      "                         'category': '일반행정',\n",
      "                         'size': 'small',\n",
      "                         'char_count': 377,\n",
      "                         'publish_date': '19841226',\n",
      "                         'title': '부당노동행위구제재심판정취소',\n",
      "                         'text': [   [   {   'index': 0,\n",
      "                                             'sentence': '원고가 소속회사의 노동조합에서 분규가 '\n",
      "                                                         '발생하자 노조활동을 구실로 정상적인 '\n",
      "                                                         '근무를 해태하고,',\n",
      "                                             'highlight_indices': ''},\n",
      "                                         {   'index': 1,\n",
      "                                             'sentence': '노조조합장이 사임한 경우,',\n",
      "                                             'highlight_indices': ''},\n",
      "                                         {   'index': 2,\n",
      "                                             'sentence': '노동조합규약에 동 조합장의 직무를 '\n",
      "                                                         '대행할 자를 규정해 두고 있음에도 '\n",
      "                                                         '원고 자신이 주동하여 '\n",
      "                                                         '노조자치수습대책위원회를 구성하여 그 '\n",
      "                                                         '위원장으로 피선되어 근무시간중에도 '\n",
      "                                                         '노조활동을 벌여 운수업체인 소속회사의 '\n",
      "                                                         '업무에 지장을 초래하고',\n",
      "                                             'highlight_indices': '8,9;68,69'},\n",
      "                                         {   'index': 3,\n",
      "                                             'sentence': '종업원들에게도 나쁜 영향을 끼쳐 '\n",
      "                                                         '소속회사가 취업규칙을 위반하고',\n",
      "                                             'highlight_indices': ''},\n",
      "                                         {   'index': 4,\n",
      "                                             'sentence': '고의로 회사업무능률을 저해하였으며 '\n",
      "                                                         '회사업무상의 지휘명령에 위반하였음을 '\n",
      "                                                         '이유로 원고를 징계해고 하였다면,',\n",
      "                                             'highlight_indices': '0,3'},\n",
      "                                         {   'index': 5,\n",
      "                                             'sentence': '이는 원고의 노동조합 활동과는 '\n",
      "                                                         '관계없이 회사취업규칙에 의하여 '\n",
      "                                                         '사내질서를 유지하기 위한 사용자 '\n",
      "                                                         '고유의 징계권에 기하여 이루어진 '\n",
      "                                                         '정당한 징계권의 행사로 보아야 한다.',\n",
      "                                             'highlight_indices': '17,21'}]],\n",
      "                         'annotator_id': 3783,\n",
      "                         'document_quality_scores': {   'readable': 3,\n",
      "                                                        'accurate': 3,\n",
      "                                                        'informative': 3,\n",
      "                                                        'trustworthy': 3},\n",
      "                         'extractive': [5, 4, 2],\n",
      "                         'abstractive': [   '원고가  주동하여 회사업무능률을 저해하고 회사업무상의 '\n",
      "                                            '지휘명령에 위반하였다면 이에 따른 징계해고는 사내질서를 '\n",
      "                                            '유지하기 위한 사용자 고유의 정당한 징계권의 행사로 보아야 '\n",
      "                                            '한다.']},\n",
      "                     {   'id': '83586',\n",
      "                         'category': '민사',\n",
      "                         'size': 'small',\n",
      "                         'char_count': 491,\n",
      "                         'publish_date': '20041126',\n",
      "                         'title': '손해배상(자)',\n",
      "                         'text': [   [   {   'index': 0,\n",
      "                                             'sentence': '[1] 교통사고 피해자의 기왕증이 그 '\n",
      "                                                         '사고와 경합하여 악화됨으로써 '\n",
      "                                                         '피해자에게 특정 상해의 발현 또는 '\n",
      "                                                         '치료기간의 장기화,',\n",
      "                                             'highlight_indices': '19,20;53,55'},\n",
      "                                         {   'index': 1,\n",
      "                                             'sentence': '나아가 치료종결 후 후유장해 정도의 '\n",
      "                                                         '확대라는 결과 발생에 기여한 '\n",
      "                                                         '경우에는,',\n",
      "                                             'highlight_indices': ''},\n",
      "                                         {   'index': 2,\n",
      "                                             'sentence': '기왕증이 그 특정 상해를 포함한 상해 '\n",
      "                                                         '전체의 결과 발생에 대하여 '\n",
      "                                                         '기여하였다고 인정되는 정도에 따라 '\n",
      "                                                         '피해자의 전 손해 중 그에 상응한 '\n",
      "                                                         '배상액을 부담케 하는 것이 손해의 '\n",
      "                                                         '공평한 부담이라는 견지에서 타당하고,',\n",
      "                                             'highlight_indices': '5,6;60,61'},\n",
      "                                         {   'index': 3,\n",
      "                                             'sentence': '법원이 기왕증의 상해 전체에 대한 '\n",
      "                                                         '기여도를 정함에 있어서는 반드시 '\n",
      "                                                         '의학상으로 정확히 판정하여야 하는 '\n",
      "                                                         '것은 아니며,',\n",
      "                                             'highlight_indices': '33,36;43,46'},\n",
      "                                         {   'index': 4,\n",
      "                                             'sentence': '변론에 나타난 기왕증의 원인과 정도,',\n",
      "                                             'highlight_indices': ''},\n",
      "                                         {   'index': 5,\n",
      "                                             'sentence': '상해의 부위 및 정도,',\n",
      "                                             'highlight_indices': '7,8'},\n",
      "                                         {   'index': 6,\n",
      "                                             'sentence': '기왕증과 전체 상해와의 상관관계,',\n",
      "                                             'highlight_indices': ''},\n",
      "                                         {   'index': 7,\n",
      "                                             'sentence': '치료경과, 피해자의 연령과 직업 및 '\n",
      "                                                         '건강상태 등 제반 사정을 고려하여 '\n",
      "                                                         '합리적으로 판단할 수 있다.',\n",
      "                                             'highlight_indices': '18,19'}],\n",
      "                                     [   {   'index': 8,\n",
      "                                             'sentence': '[2] 교통사고 피해자의 기왕증 등이 '\n",
      "                                                         '손해 확대에 기여한 부분이 있음에도,',\n",
      "                                             'highlight_indices': ''},\n",
      "                                         {   'index': 9,\n",
      "                                             'sentence': '입원치료기간 중의 일실수입을 산정함에 '\n",
      "                                                         '있어 이를 참작하지 않은 원심판결을 '\n",
      "                                                         '파기한 사례.',\n",
      "                                             'highlight_indices': '43,44'}]],\n",
      "                         'annotator_id': 3684,\n",
      "                         'document_quality_scores': {   'readable': 4,\n",
      "                                                        'accurate': 4,\n",
      "                                                        'informative': 4,\n",
      "                                                        'trustworthy': 4},\n",
      "                         'extractive': [0, 2, 9],\n",
      "                         'abstractive': [   '교통사고 피해자의 기왕증이 그 사고와 합쳐져 악화됨으로써 '\n",
      "                                            '피해자에게 특정 상해의 발현 또는 치료기간의 장기화에 영향을 '\n",
      "                                            '준 때에는 기왕증이 그 특정 상해를 포함한 상해 전체의 결과 '\n",
      "                                            '발생에 대하여 영향을 주었다고 판단되는 정도에 따라 피해자의 '\n",
      "                                            '모든 손해 중 그에 상응한 배상액을 부담케 하는 것이 손해의 '\n",
      "                                            '공평한 부담이라는 견지에서 타당하다 할 것인바, 교통사고 '\n",
      "                                            '피해자의 기왕증 등이 손해 확대에 영향을 미친 부분이 있으면 '\n",
      "                                            '입원치료기간 중의 일실수입을 산정함에 있어 이를 참작하여야 '\n",
      "                                            '한다.']}]}\n"
     ]
    }
   ],
   "source": [
    "def print_sample(sample: dict):\n",
    "    tmp = copy.deepcopy(sample)\n",
    "    tmp[\"documents\"] = [tmp[\"documents\"][0], tmp[\"documents\"][-1]]\n",
    "    pprint.PrettyPrinter(indent=4, sort_dicts=False).pprint(tmp)\n",
    "\n",
    "## Print sample.\n",
    "with open(args.tr_law_data, \"r\") as f:\n",
    "    sample = json.loads(f.read())\n",
    "    \n",
    "print_sample(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a04962-763d-4516-86ae-ecbdf7f016ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Fix Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520c32c-c132-461f-8cac-166fda613b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = args.seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939b729-5048-48b2-a017-7fb3b1f738d8",
   "metadata": {},
   "source": [
    "### **DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee5dbcf6-959f-4fe5-9f56-eeac688b9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28089d3c-b896-49a2-8027-e6d6fe8d02de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a23816b9-0a81-494d-b947-01d783c1ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [\n",
    "    \"치료경과, 피해자의 연령과 직업 및 건강상태 등 제반 사정을 고려하여 합리적으로 판단할 수 있다.\",\n",
    "    \"[2] 교통사고 피해자의 기왕증 등이 손해 확대에 기여한 부분이 있음에도,\",\n",
    "    \"입원치료기간 중의 일실수입을 산정함에 있어 이를 참작하지 않은 원심판결을 파기한 사례.\",\n",
    "]\n",
    "\n",
    "## Encode the inputs per each sentences and concat all.\n",
    "inp = [tokenizer.encode(i, max_length=int(512 / len(inp)), truncation=True, add_special_tokens=True) for i in inp]\n",
    "inp = np.array(list(itertools.chain.from_iterable(inp)))\n",
    "\n",
    "## Generate 'cls' s.t. means the index of tokens.\n",
    "cls = np.concatenate([np.where(inp == tokenizer.cls_token_id)[0], [len(inp)]])\n",
    "\n",
    "seg = list(itertools.starmap(lambda x, y: [x] * y, zip(np.arange(len(np.diff(cls))) % 2, np.diff(cls))))\n",
    "\n",
    "# seg = [[0] * (cls[i+1] - cls[i]) if i % 2 == 0 else [1] * (cls[i+1] - cls[i]) for i, _ in enumerate(cls[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cef18969-10d5-4b0d-8299-7fac05d0becc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26, 19, 24]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i) for i in seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f20659-d9d6-45a7-a987-d34da00b54c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284e28e-82db-4593-9a89-11fd1d941440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5af43bb6-8623-41ea-8382-45ac6a4a3f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 26, 45, 69]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(i) for i in seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d5f5fc3-8bb3-4af7-aaa8-45adaba8c817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 19, 24])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2cd800-1ca1-4669-965d-2e62390468e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59d48f-111c-4870-81f2-9c37200762a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d23389d-5e68-42a1-a10f-f19bf6276b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(bb == tokenizer.cls_token_id)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ea137e7-c4c1-4e21-a479-af9fffb5328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c793e-0b25-4509-9a1d-833c7fc334da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f96867-a799-45ec-89f3-81cb3ec940f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db6a6535-f545-4366-a13a-a096a6cee744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(bb == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7486599-eb7b-4c94-9bb5-b3de68cd3447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]),)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([1, 2, 3])\n",
    "np.where(aa == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b03f39-c6fa-40c8-95d2-6615b3e12ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "54fbaa69-19c5-438e-a694-660d13bd7abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([2, 3])\n",
    "np.sum(np.eye(5)[aa, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0717df-0be1-4afb-8104-ad7d36c80b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de561e50-f10c-4b9e-a25c-9467279ace9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        data_path: Path, \n",
    "        vocab_size: int = 512,\n",
    "        inp_pad_id: int = 0,\n",
    "        cls_pad_id: int = -1,\n",
    "        seg_pad_id: int = 0,\n",
    "    ):\n",
    "        self.documents = get_documents(data_path)\n",
    "        self.vocab_size = vocab_size ## maximum embedding length\n",
    "        self.inp_pad_id = inp_pad_id\n",
    "        self.cls_pad_id = cls_pad_id\n",
    "        self.seg_pad_id = seg_pad_id\n",
    "        \n",
    "        self.data = self.data_loader(documents)\n",
    "        \n",
    "        \n",
    "    def get_documents(self, data_path: Path) -> list:\n",
    "        documents = []\n",
    "        for file_path in sorted(list(data_path.glob(\"*.json\"))):\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                document = json.loads(f.read()) ## list type -> not append, but extent\n",
    "            documents.extend(document[\"documents\"])\n",
    "\n",
    "        return documents\n",
    "        \n",
    "\n",
    "    def data_loader(self, documents: list) -> dict:\n",
    "        data = {\"inp\": [], \"cls\": [], \"seg\": [], \"msk\": [], \"msk_cls\": [], \"tar_ext\": [], \"tar_abs\": []}\n",
    "        for document in documents:\n",
    "            ## Input.\n",
    "            inp = [sentence[\"sentence\"] for sentence in itertools.chain(*document[\"text\"])]\n",
    "            inp, cls, seg = self.tokenizing(inp)\n",
    "            \n",
    "            ## Extractive target.\n",
    "            tar_ext = document[\"extractive\"]\n",
    "            \n",
    "            ## Abstractive target.\n",
    "            tar_abs = document[\"abstractive\"][0] ## flatten\n",
    "            \n",
    "            ## Append.\n",
    "            data[\"inp\"].append(inp)\n",
    "            data[\"cls\"].append(cls)\n",
    "            data[\"seg\"].append(seg)\n",
    "            data[\"tar_ext\"].append(tar_ext)\n",
    "            data[\"tar_abs\"].append(tar_abs)\n",
    "            \n",
    "        ## Calculate max length.\n",
    "        max_inp_len = max([len(i) for i in data[\"inp\"]]) ## max(#(vocabs))\n",
    "        max_cls_len = max([len(i) for i in data[\"cls\"]]) ## max(#(sentences))\n",
    "\n",
    "        ## Apply padding and calculate masking.\n",
    "        for i in range(len(data[\"inp\"])):\n",
    "            inp, seg, cls, msk, msk_cls = self.padding(data[\"inp\"][i], data[\"seg\"][i], data[\"cls\"][i], max_inp_len, max_cls_len)\n",
    "            tar_ext = self.one_hot_encoding(data[\"tar\"][i], max_cls_len)\n",
    "            \n",
    "            ## Append or modify.\n",
    "            data[\"inp\"][i] = inp\n",
    "            data[\"seg\"][i] = seg\n",
    "            data[\"cls\"][i] = cls\n",
    "            \n",
    "            data[\"msk\"].append(msk)\n",
    "            data[\"msk_cls\"].append(msk_cls)\n",
    "            \n",
    "            data[\"tar\"][i] = tar\n",
    "            \n",
    "        return data\n",
    "    \n",
    "        \n",
    "    def cleaning(self, sentence: str) -> str:\n",
    "        pass\n",
    "            \n",
    "            \n",
    "    def tokenizing(self, inp: list) -> tuple:\n",
    "        \"\"\" 각 sentence 별로 tokenizer를 이용한 인코딩 후 cls 및 seg 값을 계산합니다.\n",
    "        \"\"\"\n",
    "        ## Encode the inputs per each sentences and concat all.\n",
    "        inp = [self.tokenizer.encode(i, max_length=int(self.vocab_size / len(inp)), truncation=True, add_special_tokens=True) for i in inp]\n",
    "        inp = np.array(list(itertools.chain.fron_iterable(inp)))\n",
    "        \n",
    "        ## Generate 'cls' s.t. means the index of tokens.\n",
    "        cls = np.concatenate([np.where(i == self.tokenizer.cls_token_id)[0], len(inp)])\n",
    "        \n",
    "        ## Generate 'seg' s.t. means segmentation embeddings which represented as [0, 0, ..., 0, 1, ..., 1, 0, 0, ...].\n",
    "        seg = list(itertools.starmap(lambda x, y: [x] * y, zip(np.arange(len(np.diff(cls))) % 2, np.diff(cls))))\n",
    "        seg = np.array(list(itertools.chain.from_iterable(seg)))\n",
    "        \n",
    "        cls = cls[:-1]\n",
    "        \n",
    "        return inp, cls, seg\n",
    "    \n",
    "    \n",
    "    def padding(self, inp: list, seg: list, cls: list, max_inp_len: int, max_cls_len: int) -> tuple:\n",
    "        \"\"\" 각 sentence 별로 정해진 길이에 맞추어 inp, cls, seg 값을 패딩 처리합니다.\n",
    "        \"\"\"\n",
    "        ## Pad all.\n",
    "        inp = np.concatenate([inp, np.array([self.inp_pad_id] * (max_inp_len - len(inp)))])\n",
    "        seg = np.concatenate([seg, np.array([self.seg_pad_id] * (max_inp_len - len(seg)))])\n",
    "        cls = np.concatenate([cls, np.array([self.cls_pad_id] * (max_cls_len - len(cls)))])\n",
    "        \n",
    "        ## Generate msking value.\n",
    "        msk = ~(np.where(inp == self.inp_pad_id)[0])\n",
    "        msk_cls = ~(np.where(cls == self.cls_pad_id)[0])\n",
    "        \n",
    "        return inp, seg, cls, msk, msk_cls\n",
    "    \n",
    "    \n",
    "    def one_hot_encoding(self, tar: list, max_cls_len: int) -> list:\n",
    "        return np.sum(np.eye(max_cls_len)[np.array(tar), :], axis=0)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\" 데이터 세트의 전체 크기(길이)를 반환\n",
    "        \"\"\"\n",
    "        return len(self.data[\"inp\"])\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" idx 번째 샘플을 반환\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"inp\": self.data[\"inp\"][idx],\n",
    "            \"seg\": self.data[\"seg\"][idx],\n",
    "            \"cls\": self.data[\"cls\"][idx],\n",
    "            \"msk\": self.data[\"msk\"][idx],\n",
    "            \"msk_cls\": self.data[\"msk_cls\"][idx],\n",
    "            \"tar_ext\": self.data[\"tar_ext\"]\n",
    "        }\n",
    "        \n",
    "        return [self.inputs[idx][i] for i in range(5)], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644200a-7426-41cc-b968-893a968ae164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-torch",
   "language": "python",
   "name": "py38-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
