## EDA
# python eda.py \
#     --raw_train ./data/raw/Training \
#     --raw_valid ./data/raw/Validation \
#     --raw_test ./data/raw/Test2

## Preprocess
python preprocess.py \
    --raw_train ./data/raw/Training \
    --raw_valid ./data/raw/Validation \
    --raw_test ./data/raw/Test2

## Make dev dataset.
head -n 1000 ./data/corpus.train.if > ./data/corpus.train.dev.if &
head -n 1000 ./data/corpus.train.of > ./data/corpus.train.dev.of &
head -n 1000 ./data/corpus.valid.if > ./data/corpus.valid.dev.if &
head -n 1000 ./data/corpus.valid.of > ./data/corpus.valid.dev.of &

## Train: native
python finetune_plm_native.py \
    --train ./data/corpus.train.dev \
    --valid ./data/corpus.valid.dev \
    --gpu_id 0 \
    --max_grad_norm 1e+8 \
    --batch_size 48 \
    --lr 5e-5 \
    --n_epochs 5 \
    --use_radam \
    --model_fpath hft.gogamza.kobart-summarization.bs-48.lr-5e-5.warmup-2.radam.dev

## Train: hftariner.
python finetune_plm_hftrainer.py \
    --train ./data/train.tsv \
    --valid ./data/valid.tsv \
    --pretrained_model_name gogamza/kobart-base-v1 \
    --per_replica_batch_size 16 \
    --lr 5e-5 \
    --weight_decay 1e-2 \
    --gradient_accumulation_steps 8 \
    --n_epochs 10 \
    --model_fpath hft.gogamza.kobart-base-v1.bs-16*2*8.lr-5e-5.wd-1e-2.warmup-2.adamw

## Inference.
python summarize.py \
    --test ./data/test.tsv \
    --model_fpath ./ckpt/20211205-164445/hft.gogamza.kobart-base-v1.bs-16*2*8.lr-5e-5.wd-1e-2.warmup-2.adamw.pth \
    --gpu_id 1 \
    --length_penalty 0.8 \
    --batch_size 64

## Auto-submission API.
wget -O dacon_submit_api-0.0.4-py3-none-any.zip https://bit.ly/3gMPScE
unzip dacon_submit_api-0.0.4-py3-none-any.zip
pip install dacon_submit_api-0.0.4-py3-none-any.whl

## Remote server terminal.
(server) tensorboard --logdir ./logs/20211205-164445/run --port 8888 --bind_all
